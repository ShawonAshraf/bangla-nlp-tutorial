{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['steve', 'is', 'a', 'minion', 'he', 'likes', 'bannas', 'steve', 'wants', 'to', 'eat', 'bannas']\n"
     ]
    }
   ],
   "source": [
    "corpus = \"steve is a minion. he likes bannas. steve wants to eat bannas.\"\n",
    "# remove .\n",
    "corpus = corpus.replace(\".\", \"\")\n",
    "\n",
    "tokens = corpus.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eat': 0, 'a': 1, 'minion': 2, 'bannas': 3, 'is': 4, 'he': 5, 'steve': 6, 'wants': 7, 'to': 8, 'likes': 9}\n"
     ]
    }
   ],
   "source": [
    "token_to_idx = {token: idx for idx, token in enumerate(set(tokens))}\n",
    "print(token_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'steve': 2, 'bannas': 2, 'is': 1, 'a': 1, 'minion': 1, 'he': 1, 'likes': 1, 'wants': 1, 'to': 1, 'eat': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "token_counts = Counter(tokens)\n",
    "print(token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set(tokens)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 2., 1., 1., 2., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "bag_of_words = torch.zeros(len(vocabulary))\n",
    "for token in tokens:\n",
    "    bag_of_words[token_to_idx[token]] += 1\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'eat', 1: 'a', 2: 'minion', 3: 'bannas', 4: 'is', 5: 'he', 6: 'steve', 7: 'wants', 8: 'to', 9: 'likes'}\n"
     ]
    }
   ],
   "source": [
    "idx_to_token = {idx: token for token, idx in token_to_idx.items()}\n",
    "print(idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 2., 0., 0., 2., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "def create_sentence_vector(sent: str) -> torch.Tensor:\n",
    "    tokens = sent.split()\n",
    "    sentence_vector = torch.zeros(len(vocabulary))\n",
    "\n",
    "    for token in tokens:\n",
    "        if token in token_to_idx:\n",
    "            sentence_vector[token_to_idx[token]] = bag_of_words[token_to_idx[token]]\n",
    "    return sentence_vector\n",
    "\n",
    "print(create_sentence_vector(\"steve likes bannas\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bangla-nlp-tutorial-DsP3DYQO-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
